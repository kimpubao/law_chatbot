from huggingface_hub import snapshot_download

# ê¸°ì¡´ 7.8B ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì½”ë“œ
# snapshot_download(
#     repo_id="LGAI-EXAONE/EXAONE-3.5-7.8B-instruct",
#     local_dir="EXAONE-3.5-7.8B-Instruct",
#     local_dir_use_symlinks=False
# )



# ìƒˆë¡­ê²Œ 2.4B ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
# snapshot_download(
#     repo_id="LGAI-EXAONE/EXAONE-3.5-2.4B-instruct",
#     local_dir="EXAONE-3.5-2.4B-Instruct",
#     local_dir_use_symlinks=False
# )



from transformers import AutoTokenizer, AutoModel
import os

# ì €ì¥í•  í´ë”
save_dir = "./models"

# ë‹¤ìš´ë¡œë“œ ëŒ€ìƒ ëª¨ë¸ë“¤
models_to_download = {
    "klue/roberta-base": "klue_roberta_base",
    "beomi/KcELECTRA-base-v2022": "kc_electra_base_v2022"
}

# ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
for model_id, folder_name in models_to_download.items():
    local_path = os.path.join(save_dir, folder_name)
    print(f"ğŸ”½ ë‹¤ìš´ë¡œë“œ ì¤‘: {model_id} â†’ {local_path}")
    
    AutoTokenizer.from_pretrained(model_id, cache_dir=local_path)
    AutoModel.from_pretrained(model_id, cache_dir=local_path)

print("âœ… ëª¨ë“  ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ.")