# from huggingface_hub import snapshot_download

# ê¸°ì¡´ 7.8B ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì½”ë“œ
# snapshot_download(
#     repo_id="LGAI-EXAONE/EXAONE-3.5-7.8B-instruct",
#     local_dir="EXAONE-3.5-7.8B-Instruct",
#     local_dir_use_symlinks=False
# )



# ìƒˆë¡­ê²Œ 2.4B ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
# snapshot_download(
#     repo_id="LGAI-EXAONE/EXAONE-3.5-2.4B-instruct",
#     local_dir="EXAONE-3.5-2.4B-Instruct",
#     local_dir_use_symlinks=False
# )


from transformers import AutoTokenizer, AutoModelForCausalLM
import os

# ì €ì¥ ê²½ë¡œ
save_dir_polyglot = "models/polyglot-ko-1.3b"
save_dir_kogpt2 = "models/kogpt2-base-v2"

# ëª¨ë¸ ID
polyglot_id = "EleutherAI/polyglot-ko-1.3b"
kogpt2_id = "skt/kogpt2-base-v2"

# Polyglot-Ko 1.3B ë‹¤ìš´ë¡œë“œ
print("ğŸ”½ polyglot-ko-1.3b ë‹¤ìš´ë¡œë“œ ì¤‘...")
AutoTokenizer.from_pretrained(polyglot_id).save_pretrained(save_dir_polyglot)
AutoModelForCausalLM.from_pretrained(polyglot_id).save_pretrained(save_dir_polyglot)
print("âœ… polyglot-ko-1.3b ì €ì¥ ì™„ë£Œ:", save_dir_polyglot)

# KoGPT2 ë‹¤ìš´ë¡œë“œ
print("ğŸ”½ kogpt2-base-v2 ë‹¤ìš´ë¡œë“œ ì¤‘...")
AutoTokenizer.from_pretrained(kogpt2_id).save_pretrained(save_dir_kogpt2)
AutoModelForCausalLM.from_pretrained(kogpt2_id).save_pretrained(save_dir_kogpt2)
print("âœ… kogpt2-base-v2 ì €ì¥ ì™„ë£Œ:", save_dir_kogpt2)
